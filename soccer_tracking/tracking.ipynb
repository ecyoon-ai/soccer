{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1aElPohr0BrXnWridwQenJoiG5WTGMyq7","authorship_tag":"ABX9TyMYkgCY/oatgFgY2YUb2hHW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"udfL-jh-Kx4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747453754688,"user_tz":-540,"elapsed":191370,"user":{"displayName":"Ïù¥ÌûòÏ∞¨","userId":"10220646054598307609"}},"outputId":"c09ec433-8220-4c03-e18d-95aea21fcfcb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless==4.9.0.80\n","  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless==4.9.0.80) (1.26.4)\n","Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: opencv-python-headless\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.11.0.86\n","    Uninstalling opencv-python-headless-4.11.0.86:\n","      Successfully uninstalled opencv-python-headless-4.11.0.86\n","Successfully installed opencv-python-headless-4.9.0.80\n","Collecting boxmot==12.0.1\n","  Downloading boxmot-12.0.1-py3-none-any.whl.metadata (12 kB)\n","Collecting filterpy<2.0.0,>=1.4.5 (from boxmot==12.0.1)\n","  Downloading filterpy-1.4.5.zip (177 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy<7.0.0,>=6.1.3 (from boxmot==12.0.1)\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: gdown<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (5.2.0)\n","Requirement already satisfied: gitpython<4.0.0,>=3.1.42 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (3.1.44)\n","Collecting lapx<0.6.0,>=0.5.5 (from boxmot==12.0.1)\n","  Downloading lapx-0.5.11.post1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n","Collecting loguru<0.8.0,>=0.7.2 (from boxmot==12.0.1)\n","  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (1.26.4)\n","Requirement already satisfied: opencv-python<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (4.11.0.86)\n","Requirement already satisfied: pandas<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (2.2.2)\n","Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (6.0.2)\n","Requirement already satisfied: regex<2025.0.0,>=2024.0.0 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (2024.11.6)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (1.6.1)\n","Requirement already satisfied: torch<3.0.0,>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from boxmot==12.0.1) (2.5.1+cu124)\n","Collecting torchvision<0.18.0,>=0.17.1 (from boxmot==12.0.1)\n","  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting yacs<0.2.0,>=0.1.8 (from boxmot==12.0.1)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (1.13.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (3.10.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0.0,>=6.1.3->boxmot==12.0.1) (0.2.13)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (4.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (3.17.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (4.67.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4.0.0,>=3.1.42->boxmot==12.0.1) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.0.0->boxmot==12.0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.0.0->boxmot==12.0.1) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.0.0->boxmot==12.0.1) (2025.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->boxmot==12.0.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.3.0->boxmot==12.0.1) (3.5.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.2.1->boxmot==12.0.1) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.2.1->boxmot==12.0.1) (1.3.0)\n","Collecting torch<3.0.0,>=2.2.1 (from boxmot==12.0.1)\n","  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision<0.18.0,>=0.17.1->boxmot==12.0.1) (11.1.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.2.0 (from torch<3.0.0,>=2.2.1->boxmot==12.0.1)\n","  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.2.1->boxmot==12.0.1) (12.5.82)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.42->boxmot==12.0.1) (5.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->boxmot==12.0.1) (1.17.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (2.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.2.1->boxmot==12.0.1) (3.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->boxmot==12.0.1) (3.2.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (2025.1.31)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown<6.0.0,>=5.1.0->boxmot==12.0.1) (1.7.1)\n","Downloading boxmot-12.0.1-py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lapx-0.5.11.post1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: filterpy\n","  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=fff962499ab8d3097fdac8cc35a54c2cd1a3344814c7f7d2223d83ad834ceb91\n","  Stored in directory: /root/.cache/pip/wheels/12/dc/3c/e12983eac132d00f82a20c6cbe7b42ce6e96190ef8fa2d15e1\n","Successfully built filterpy\n","Installing collected packages: yacs, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, lapx, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, filterpy, torch, torchvision, boxmot\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu124\n","    Uninstalling torchvision-0.20.1+cu124:\n","      Successfully uninstalled torchvision-0.20.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed boxmot-12.0.1 filterpy-1.4.5 ftfy-6.3.1 lapx-0.5.11.post1 loguru-0.7.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0 yacs-0.1.8\n","Collecting ultralytics\n","  Downloading ultralytics-8.3.137-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.17.2)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.3.137-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.137 ultralytics-thop-2.0.14\n"]}],"source":["# Install only the headless version of OpenCV\n","!pip install opencv-python-headless==4.9.0.80\n","\n","# Install boxmot (includes DeepOcSort tracker and correct numpy version)\n","!pip install boxmot==12.0.1\n","\n","# Install Ultralytics for the YOLO model\n","!pip install ultralytics"]},{"cell_type":"code","source":["! kill -9 $(ps -A | grep python | awk '{print $1}')"],"metadata":{"id":"WDxf7BoHNi_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from collections import defaultdict, deque\n","from pathlib import Path\n","from ultralytics import YOLO\n","from boxmot import DeepOcSort\n","import os"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IKQ3mLvOwCp","executionInfo":{"status":"ok","timestamp":1747453782269,"user_tz":-540,"elapsed":12893,"user":{"displayName":"Ïù¥ÌûòÏ∞¨","userId":"10220646054598307609"}},"outputId":"e8160862-ccc6-4fc6-9c6b-163f59b25672"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","source":["def track_humans(input_video, output_video):\n","    # Initialize the YOLO model for detecting humans\n","    human_detector = YOLO(\"yolo11x.pt\")\n","    # Initialize the DeepOcSort tracker for tracking detected people\n","    human_tracker = DeepOcSort(\n","        asso_func=\"ciou\",  # Association function for matching detections to tracks\n","        reid_weights=Path(\"osnet_x0_25_msmt17.pt\"),  # Model weights for re-identification\n","        device=\"cuda:0\",   # Run on GPU (cuda:0)\n","        half=True,         # Use half-precision for faster inference\n","        det_thresh=0.5,    # Detection confidence threshold\n","        max_age=30,        # Max frames to keep 'lost' tracks\n","        min_hits=3,        # Min detections before a new track is confirmed\n","        iou_threshold=0.3, # IOU threshold for matching\n","        delta_t=3,         # Tracker parameter (time window)\n","        inertia=0.2,       # Tracker smoothing parameter\n","        w_association_emb=0.5,\n","        alpha_fixed_emb=0.95,\n","        aw_param=0.5,\n","        embedding_off=False,\n","        cmc_off=False,\n","        aw_off=False,\n","        new_kf_off=False,\n","        use_cuda=True\n","    )\n","\n","    # Open the input video file\n","    video_reader = cv2.VideoCapture(input_video)\n","    if not video_reader.isOpened():\n","        return  # Exit if the video could not be opened\n","\n","    # Get video information: frame rate, width, height\n","    fps = video_reader.get(cv2.CAP_PROP_FPS)\n","    width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    # Prepare to write the output video\n","    video_writer = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n","\n","    # Set font sizes and thickness for annotations\n","    base_scale = height / 500\n","    base_thickness = max(1, int(height / 300))\n","    label_scale = base_scale * 0.6\n","    label_thickness = max(1, base_thickness - 1)\n","\n","    # Initialize variables for tracking people\n","    human_history = defaultdict(lambda: deque(maxlen=60))  # Stores recent positions for each person\n","    last_positions = {}           # Stores last position for each ID to check for jumps\n","    position_threshold = 50       # Ignore sudden large jumps in position (pixels)\n","    frame_count = 0               # Frame counter\n","\n","    while True:\n","        ret, frame = video_reader.read()\n","        if not ret:\n","            break  # End of video\n","\n","        # Detect humans in the frame using YOLO\n","        human_results = human_detector(frame, conf=0.1)\n","        human_detections = []\n","        for box in human_results[0].boxes:\n","            bbox = box.xyxy.cpu().numpy()[0]      # Bounding box coordinates\n","            conf = float(box.conf.item())         # Detection confidence\n","            cls = int(box.cls.item())             # Class ID (0: person in COCO dataset)\n","            if cls == 0:  # Only keep person detections\n","                human_detections.append([bbox[0], bbox[1], bbox[2], bbox[3], conf, cls])\n","\n","        # Convert detections to numpy array for the tracker\n","        human_detections = np.array(human_detections) if human_detections else np.empty((0, 6))\n","\n","        # Track the detected humans using DeepOcSort\n","        try:\n","            human_tracks = human_tracker.update(human_detections, frame)\n","        except IndexError:\n","            human_tracks = []\n","\n","        # Copy the frame to draw annotations\n","        annotated_frame = frame.copy()\n","        for track in human_tracks:\n","            bbox = track[:4]          # Bounding box coordinates\n","            track_id = int(track[4])  # Unique ID for the tracked person\n","            confidence = track[5] if len(track) > 5 else 1.0  # Tracking confidence\n","\n","            # Calculate the center of the bounding box\n","            center = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n","\n","            # Check for sudden large position changes (to avoid ID switches or errors)\n","            if track_id in last_positions:\n","                last_pos = last_positions[track_id]\n","                distance = np.linalg.norm(np.array(center) - np.array(last_pos))\n","                if distance > position_threshold:\n","                    continue  # Ignore if jump is too large\n","\n","            # Save the current position\n","            last_positions[track_id] = center\n","            # Add the center to the trajectory history\n","            human_history[track_id].append(center)\n","\n","            # Ignore bounding boxes that are too large (likely errors)\n","            bbox_width = bbox[2] - bbox[0]\n","            bbox_height = bbox[3] - bbox[1]\n","            bbox_area = bbox_width * bbox_height\n","            if bbox_area > (width * height) / 4:\n","                continue\n","\n","            # Set color and thickness based on confidence\n","            color = (0, 255, 0) if confidence >= 0.5 else (0, 0, 255)\n","            thickness = 2 if confidence >= 0.5 else 1\n","\n","            # Draw the bounding box around the person\n","            cv2.rectangle(annotated_frame, (int(bbox[0]), int(bbox[1])),\n","                          (int(bbox[2]), int(bbox[3])), color, thickness)\n","\n","            # Draw the tracking ID and confidence above the box\n","            cv2.putText(annotated_frame, f\"ID:{track_id} ({confidence:.2f})\",\n","                        (int(bbox[0]), int(bbox[1]) - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, label_scale, color, label_thickness)\n","\n","            # Draw the movement trajectory for each tracked person\n","            if len(human_history[track_id]) >= 2:\n","                for i in range(1, len(human_history[track_id])):\n","                    pt1 = (int(human_history[track_id][i-1][0]), int(human_history[track_id][i-1][1]))\n","                    pt2 = (int(human_history[track_id][i][0]), int(human_history[track_id][i][1]))\n","                    # Assign a unique color to each track using the ID\n","                    track_color = (int(track_id * 50) % 255,\n","                                   int(track_id * 100) % 255,\n","                                   int(track_id * 150) % 255)\n","                    cv2.line(annotated_frame, pt1, pt2, track_color, 2)\n","\n","        # Save the annotated frame to the output video\n","        video_writer.write(annotated_frame)\n","        frame_count += 1\n","\n","    # Release video resources when done\n","    video_reader.release()\n","    video_writer.release()\n","\n","if __name__ == \"__main__\":\n","    # Define input and output directories\n","    input_dir = \"/content/drive/MyDrive/Colab Notebooks/soccer_prj/soccer_tracking/soccer_input\"\n","    output_dir = \"/content/drive/MyDrive/Colab Notebooks/soccer_prj/soccer_tracking/soccer_output\"\n","    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n","\n","    # Process all video files in the input directory\n","    video_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.mp4', '.avi', '.mov'))]\n","    for video_file in video_files:\n","        input_path = os.path.join(input_dir, video_file)\n","        output_path = os.path.join(output_dir, f\"processed_{video_file}\")\n","        print(f\"Starting processing for video: {input_path}\")\n","        track_humans(input_path, output_path)\n","        print(f\"Finished processing for video: {input_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awV4OANuOzpP","executionInfo":{"status":"ok","timestamp":1747453838315,"user_tz":-540,"elapsed":53112,"user":{"displayName":"Ïù¥ÌûòÏ∞¨","userId":"10220646054598307609"}},"outputId":"ca39b59b-3af3-451e-c51c-1d17e24fa1f0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting processing for video: /content/drive/MyDrive/Colab Notebooks/soccer_prj/soccer_tracking/soccer_input/for_tracking.mp4\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt to 'yolo11x.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109M/109M [00:00<00:00, 348MB/s] \n","\u001b[32m2025-05-17 03:49:47.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboxmot.utils.torch_utils\u001b[0m:\u001b[36mselect_device\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mYolo Tracking v12.0.0 üöÄ Python-3.11.11 torch-2.2.2+cu121\n","CUDA:0 (Tesla T4, 15095MiB)\u001b[0m\n","Downloading...\n","From: https://drive.google.com/uc?id=1sSwXSUlj4_tHZequ_iZ8w_Jh0VaRQMqF\n","To: /content/osnet_x0_25_msmt17.pt\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.06M/3.06M [00:00<00:00, 189MB/s]\n","\u001b[32m2025-05-17 03:49:51.770\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m183\u001b[0m - \u001b[32m\u001b[1mLoaded pretrained weights from osnet_x0_25_msmt17.pt\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["\n","0: 320x640 22 persons, 2 umbrellas, 86.8ms\n","Speed: 19.5ms preprocess, 86.8ms inference, 154.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 2 umbrellas, 52.6ms\n","Speed: 2.1ms preprocess, 52.6ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 3 umbrellas, 52.6ms\n","Speed: 5.3ms preprocess, 52.6ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 2 umbrellas, 54.1ms\n","Speed: 3.0ms preprocess, 54.1ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 3 umbrellas, 52.6ms\n","Speed: 4.5ms preprocess, 52.6ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 3 umbrellas, 52.5ms\n","Speed: 3.3ms preprocess, 52.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 3 umbrellas, 59.0ms\n","Speed: 3.5ms preprocess, 59.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 23 persons, 2 umbrellas, 57.4ms\n","Speed: 5.8ms preprocess, 57.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 umbrellas, 56.4ms\n","Speed: 4.2ms preprocess, 56.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 3 umbrellas, 56.1ms\n","Speed: 3.1ms preprocess, 56.1ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 3 umbrellas, 43.3ms\n","Speed: 5.1ms preprocess, 43.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 3 umbrellas, 43.2ms\n","Speed: 5.0ms preprocess, 43.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 3 umbrellas, 43.2ms\n","Speed: 2.9ms preprocess, 43.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 3 umbrellas, 43.2ms\n","Speed: 3.6ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 2 umbrellas, 45.8ms\n","Speed: 3.4ms preprocess, 45.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 3 umbrellas, 44.9ms\n","Speed: 7.2ms preprocess, 44.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 3 umbrellas, 43.3ms\n","Speed: 4.8ms preprocess, 43.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 3 umbrellas, 43.2ms\n","Speed: 3.1ms preprocess, 43.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 3 umbrellas, 49.2ms\n","Speed: 6.9ms preprocess, 49.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 3 umbrellas, 38.0ms\n","Speed: 7.3ms preprocess, 38.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 3 umbrellas, 38.0ms\n","Speed: 4.5ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 3 umbrellas, 37.9ms\n","Speed: 3.1ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 umbrellas, 38.0ms\n","Speed: 10.9ms preprocess, 38.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 4 umbrellas, 38.0ms\n","Speed: 2.9ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 4 umbrellas, 38.0ms\n","Speed: 3.0ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 3 umbrellas, 38.0ms\n","Speed: 3.2ms preprocess, 38.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 3 umbrellas, 36.9ms\n","Speed: 3.7ms preprocess, 36.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 4 umbrellas, 37.0ms\n","Speed: 3.2ms preprocess, 37.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 4 umbrellas, 38.3ms\n","Speed: 5.8ms preprocess, 38.3ms inference, 3.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 4 umbrellas, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 3 umbrellas, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 car, 4 umbrellas, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 3 umbrellas, 36.0ms\n","Speed: 2.9ms preprocess, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 umbrella, 36.0ms\n","Speed: 3.2ms preprocess, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 3 umbrellas, 36.0ms\n","Speed: 3.0ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 3 umbrellas, 36.0ms\n","Speed: 3.3ms preprocess, 36.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 3 umbrellas, 36.2ms\n","Speed: 3.6ms preprocess, 36.2ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 3 umbrellas, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 3 umbrellas, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 5.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 2 umbrellas, 36.8ms\n","Speed: 3.2ms preprocess, 36.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 2 umbrellas, 38.5ms\n","Speed: 4.3ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 umbrellas, 42.5ms\n","Speed: 3.1ms preprocess, 42.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 13 persons, 2 cars, 1 umbrella, 40.0ms\n","Speed: 2.8ms preprocess, 40.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 2 umbrellas, 42.0ms\n","Speed: 2.9ms preprocess, 42.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 car, 2 umbrellas, 46.3ms\n","Speed: 5.4ms preprocess, 46.3ms inference, 3.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 umbrellas, 43.9ms\n","Speed: 3.3ms preprocess, 43.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 2 umbrellas, 61.2ms\n","Speed: 3.0ms preprocess, 61.2ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 car, 2 umbrellas, 53.0ms\n","Speed: 4.0ms preprocess, 53.0ms inference, 7.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 23 persons, 1 car, 2 umbrellas, 72.3ms\n","Speed: 3.2ms preprocess, 72.3ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 23 persons, 1 car, 2 umbrellas, 52.1ms\n","Speed: 3.5ms preprocess, 52.1ms inference, 6.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 2 umbrellas, 47.9ms\n","Speed: 5.9ms preprocess, 47.9ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 umbrellas, 52.4ms\n","Speed: 12.2ms preprocess, 52.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 umbrellas, 49.7ms\n","Speed: 3.8ms preprocess, 49.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 2 umbrellas, 58.4ms\n","Speed: 10.3ms preprocess, 58.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 2 umbrellas, 55.0ms\n","Speed: 3.1ms preprocess, 55.0ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 umbrellas, 56.0ms\n","Speed: 2.8ms preprocess, 56.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 2 umbrellas, 55.3ms\n","Speed: 5.9ms preprocess, 55.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 1 airplane, 1 umbrella, 77.4ms\n","Speed: 3.1ms preprocess, 77.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 55.4ms\n","Speed: 5.8ms preprocess, 55.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 umbrella, 62.8ms\n","Speed: 7.2ms preprocess, 62.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 62.6ms\n","Speed: 7.5ms preprocess, 62.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 umbrella, 57.8ms\n","Speed: 3.1ms preprocess, 57.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 72.4ms\n","Speed: 6.8ms preprocess, 72.4ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 airplane, 60.2ms\n","Speed: 5.6ms preprocess, 60.2ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 1 airplane, 57.4ms\n","Speed: 4.0ms preprocess, 57.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 1 airplane, 57.4ms\n","Speed: 3.2ms preprocess, 57.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 2 cars, 1 airplane, 57.3ms\n","Speed: 3.4ms preprocess, 57.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 1 airplane, 1 umbrella, 43.3ms\n","Speed: 3.9ms preprocess, 43.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 airplane, 43.2ms\n","Speed: 4.1ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 airplane, 1 umbrella, 43.2ms\n","Speed: 3.6ms preprocess, 43.2ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 airplane, 38.0ms\n","Speed: 3.5ms preprocess, 38.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 umbrella, 38.0ms\n","Speed: 3.4ms preprocess, 38.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 umbrella, 37.9ms\n","Speed: 3.0ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 38.7ms\n","Speed: 2.9ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 umbrella, 37.3ms\n","Speed: 3.2ms preprocess, 37.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 umbrella, 37.5ms\n","Speed: 4.1ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 37.4ms\n","Speed: 2.9ms preprocess, 37.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 37.4ms\n","Speed: 2.7ms preprocess, 37.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 37.6ms\n","Speed: 6.4ms preprocess, 37.6ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 umbrella, 37.0ms\n","Speed: 2.8ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 1 umbrella, 36.9ms\n","Speed: 3.2ms preprocess, 36.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 1 umbrella, 40.2ms\n","Speed: 7.8ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 1 umbrella, 37.0ms\n","Speed: 5.8ms preprocess, 37.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 car, 1 umbrella, 37.0ms\n","Speed: 2.7ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 1 car, 1 umbrella, 37.0ms\n","Speed: 3.2ms preprocess, 37.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 36.9ms\n","Speed: 2.7ms preprocess, 36.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 36.9ms\n","Speed: 3.3ms preprocess, 36.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 1 umbrella, 37.1ms\n","Speed: 2.9ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 umbrellas, 36.4ms\n","Speed: 2.9ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 42.7ms\n","Speed: 5.7ms preprocess, 42.7ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 37.8ms\n","Speed: 6.6ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 car, 1 umbrella, 36.6ms\n","Speed: 4.1ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 umbrella, 42.0ms\n","Speed: 3.2ms preprocess, 42.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 36.5ms\n","Speed: 3.2ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 36.4ms\n","Speed: 3.7ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 37.0ms\n","Speed: 7.6ms preprocess, 37.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 umbrella, 36.5ms\n","Speed: 3.7ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 umbrella, 39.0ms\n","Speed: 3.8ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 umbrella, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 36.5ms\n","Speed: 3.0ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 tennis racket, 40.1ms\n","Speed: 6.8ms preprocess, 40.1ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 40.3ms\n","Speed: 3.3ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 40.7ms\n","Speed: 3.8ms preprocess, 40.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 44.2ms\n","Speed: 11.7ms preprocess, 44.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 47.7ms\n","Speed: 3.0ms preprocess, 47.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 tennis racket, 42.6ms\n","Speed: 3.0ms preprocess, 42.6ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 37.5ms\n","Speed: 4.2ms preprocess, 37.5ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 37.4ms\n","Speed: 3.2ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 37.9ms\n","Speed: 3.8ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 37.4ms\n","Speed: 3.3ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 37.5ms\n","Speed: 3.7ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 37.5ms\n","Speed: 3.5ms preprocess, 37.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 37.4ms\n","Speed: 3.1ms preprocess, 37.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 37.4ms\n","Speed: 3.4ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 37.5ms\n","Speed: 3.4ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 37.0ms\n","Speed: 5.9ms preprocess, 37.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 37.8ms\n","Speed: 3.7ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 chair, 37.0ms\n","Speed: 3.2ms preprocess, 37.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 36.5ms\n","Speed: 4.2ms preprocess, 36.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 36.5ms\n","Speed: 3.4ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 36.5ms\n","Speed: 4.3ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 36.5ms\n","Speed: 3.1ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 36.5ms\n","Speed: 4.0ms preprocess, 36.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 36.6ms\n","Speed: 4.3ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 36.5ms\n","Speed: 3.9ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 sports ball, 37.1ms\n","Speed: 6.4ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 36.5ms\n","Speed: 3.1ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 38.3ms\n","Speed: 3.2ms preprocess, 38.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 36.6ms\n","Speed: 3.5ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 38.7ms\n","Speed: 5.5ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 tennis racket, 36.6ms\n","Speed: 3.4ms preprocess, 36.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 44.0ms\n","Speed: 4.9ms preprocess, 44.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 39.1ms\n","Speed: 5.2ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 39.5ms\n","Speed: 3.2ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 39.6ms\n","Speed: 3.6ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 40.3ms\n","Speed: 2.9ms preprocess, 40.3ms inference, 6.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 45.7ms\n","Speed: 5.9ms preprocess, 45.7ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 47.8ms\n","Speed: 6.0ms preprocess, 47.8ms inference, 6.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 71.3ms\n","Speed: 3.5ms preprocess, 71.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 43.9ms\n","Speed: 2.9ms preprocess, 43.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 57.4ms\n","Speed: 5.4ms preprocess, 57.4ms inference, 5.5ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 45.6ms\n","Speed: 3.4ms preprocess, 45.6ms inference, 2.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 1 train, 51.5ms\n","Speed: 3.2ms preprocess, 51.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 58.6ms\n","Speed: 7.4ms preprocess, 58.6ms inference, 6.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 1 sports ball, 53.0ms\n","Speed: 8.2ms preprocess, 53.0ms inference, 4.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 1 sports ball, 56.5ms\n","Speed: 6.3ms preprocess, 56.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 49.5ms\n","Speed: 3.2ms preprocess, 49.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 1 car, 56.8ms\n","Speed: 5.1ms preprocess, 56.8ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 51.6ms\n","Speed: 5.4ms preprocess, 51.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 2 cars, 52.6ms\n","Speed: 4.8ms preprocess, 52.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 1 airplane, 1 train, 60.3ms\n","Speed: 3.1ms preprocess, 60.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 1 airplane, 67.4ms\n","Speed: 6.0ms preprocess, 67.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 56.0ms\n","Speed: 4.8ms preprocess, 56.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 72.7ms\n","Speed: 4.9ms preprocess, 72.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 78.6ms\n","Speed: 2.7ms preprocess, 78.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 2 cars, 62.0ms\n","Speed: 6.0ms preprocess, 62.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 81.9ms\n","Speed: 3.6ms preprocess, 81.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 21 persons, 2 cars, 54.5ms\n","Speed: 5.2ms preprocess, 54.5ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 51.5ms\n","Speed: 3.2ms preprocess, 51.5ms inference, 3.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 46.1ms\n","Speed: 3.0ms preprocess, 46.1ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 45.3ms\n","Speed: 3.5ms preprocess, 45.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 45.4ms\n","Speed: 4.9ms preprocess, 45.4ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 38.0ms\n","Speed: 4.3ms preprocess, 38.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 2 cars, 40.2ms\n","Speed: 3.1ms preprocess, 40.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 37.9ms\n","Speed: 3.2ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 1 car, 1 airplane, 38.0ms\n","Speed: 4.1ms preprocess, 38.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 airplane, 37.9ms\n","Speed: 2.9ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 1 airplane, 38.0ms\n","Speed: 2.9ms preprocess, 38.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 car, 38.0ms\n","Speed: 5.7ms preprocess, 38.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 37.9ms\n","Speed: 5.6ms preprocess, 37.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 37.9ms\n","Speed: 6.2ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 car, 1 airplane, 39.7ms\n","Speed: 5.7ms preprocess, 39.7ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 car, 1 airplane, 36.5ms\n","Speed: 3.6ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 1 airplane, 36.5ms\n","Speed: 3.3ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 car, 1 airplane, 1 sports ball, 36.8ms\n","Speed: 5.4ms preprocess, 36.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 1 airplane, 36.4ms\n","Speed: 5.7ms preprocess, 36.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 36.5ms\n","Speed: 4.3ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 cars, 36.5ms\n","Speed: 2.9ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 36.5ms\n","Speed: 3.9ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 50.5ms\n","Speed: 4.0ms preprocess, 50.5ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 36.5ms\n","Speed: 4.6ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 36.5ms\n","Speed: 4.4ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 36.4ms\n","Speed: 3.0ms preprocess, 36.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 39.6ms\n","Speed: 3.9ms preprocess, 39.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 39.6ms\n","Speed: 3.6ms preprocess, 39.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 37.5ms\n","Speed: 3.9ms preprocess, 37.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 54.6ms\n","Speed: 10.4ms preprocess, 54.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 37.4ms\n","Speed: 4.2ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 37.5ms\n","Speed: 3.8ms preprocess, 37.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 car, 121.3ms\n","Speed: 3.2ms preprocess, 121.3ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 37.4ms\n","Speed: 3.4ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 40.8ms\n","Speed: 3.2ms preprocess, 40.8ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 37.7ms\n","Speed: 3.6ms preprocess, 37.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 39.0ms\n","Speed: 12.1ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 92.7ms\n","Speed: 10.6ms preprocess, 92.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 39.1ms\n","Speed: 3.0ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 43.9ms\n","Speed: 8.4ms preprocess, 43.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 47.2ms\n","Speed: 3.0ms preprocess, 47.2ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 47.4ms\n","Speed: 3.9ms preprocess, 47.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 102.4ms\n","Speed: 7.5ms preprocess, 102.4ms inference, 9.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 47.7ms\n","Speed: 3.0ms preprocess, 47.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 46.9ms\n","Speed: 3.8ms preprocess, 46.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 44.1ms\n","Speed: 3.8ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 43.2ms\n","Speed: 2.9ms preprocess, 43.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 1 car, 43.3ms\n","Speed: 4.2ms preprocess, 43.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.5ms\n","Speed: 3.9ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 40.6ms\n","Speed: 3.1ms preprocess, 40.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.5ms\n","Speed: 5.4ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.5ms\n","Speed: 5.6ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 41.8ms\n","Speed: 4.2ms preprocess, 41.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 38.4ms\n","Speed: 3.5ms preprocess, 38.4ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 39.8ms\n","Speed: 3.6ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 1 car, 1 airplane, 38.5ms\n","Speed: 5.6ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 1 airplane, 39.7ms\n","Speed: 3.3ms preprocess, 39.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 1 airplane, 38.4ms\n","Speed: 3.2ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 2 cars, 38.5ms\n","Speed: 3.5ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 car, 36.5ms\n","Speed: 4.1ms preprocess, 36.5ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 1 car, 36.5ms\n","Speed: 3.5ms preprocess, 36.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 36.4ms\n","Speed: 3.1ms preprocess, 36.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 61.2ms\n","Speed: 3.1ms preprocess, 61.2ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 36.8ms\n","Speed: 4.0ms preprocess, 36.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 36.7ms\n","Speed: 3.1ms preprocess, 36.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 35.6ms\n","Speed: 2.9ms preprocess, 35.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 49.6ms\n","Speed: 4.2ms preprocess, 49.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 37.7ms\n","Speed: 3.3ms preprocess, 37.7ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 56.9ms\n","Speed: 6.8ms preprocess, 56.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 43.7ms\n","Speed: 5.0ms preprocess, 43.7ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 35.7ms\n","Speed: 4.9ms preprocess, 35.7ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 52.7ms\n","Speed: 6.6ms preprocess, 52.7ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 46.4ms\n","Speed: 4.2ms preprocess, 46.4ms inference, 6.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 51.3ms\n","Speed: 3.2ms preprocess, 51.3ms inference, 7.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 46.1ms\n","Speed: 3.0ms preprocess, 46.1ms inference, 3.7ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 1 tennis racket, 62.6ms\n","Speed: 11.1ms preprocess, 62.6ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 54.7ms\n","Speed: 4.2ms preprocess, 54.7ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 49.4ms\n","Speed: 3.8ms preprocess, 49.4ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 48.9ms\n","Speed: 4.4ms preprocess, 48.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 67.6ms\n","Speed: 3.2ms preprocess, 67.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 51.8ms\n","Speed: 6.3ms preprocess, 51.8ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 48.9ms\n","Speed: 5.1ms preprocess, 48.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 1 airplane, 49.1ms\n","Speed: 12.8ms preprocess, 49.1ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 20 persons, 1 car, 1 airplane, 1 sports ball, 70.2ms\n","Speed: 9.3ms preprocess, 70.2ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 cars, 1 airplane, 1 sports ball, 48.0ms\n","Speed: 2.8ms preprocess, 48.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 19 persons, 2 cars, 1 airplane, 1 sports ball, 53.0ms\n","Speed: 4.5ms preprocess, 53.0ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 53.1ms\n","Speed: 2.9ms preprocess, 53.1ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 70.9ms\n","Speed: 8.7ms preprocess, 70.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 53.7ms\n","Speed: 2.8ms preprocess, 53.7ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 46.9ms\n","Speed: 2.8ms preprocess, 46.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 46.9ms\n","Speed: 3.0ms preprocess, 46.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 47.0ms\n","Speed: 4.1ms preprocess, 47.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 18 persons, 2 cars, 40.1ms\n","Speed: 3.4ms preprocess, 40.1ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 40.9ms\n","Speed: 3.1ms preprocess, 40.9ms inference, 8.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 40.3ms\n","Speed: 4.0ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.4ms\n","Speed: 3.0ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 38.4ms\n","Speed: 3.3ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 38.5ms\n","Speed: 3.7ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 38.5ms\n","Speed: 3.6ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 37.4ms\n","Speed: 2.8ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 14 persons, 2 cars, 38.2ms\n","Speed: 3.5ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 54.2ms\n","Speed: 4.3ms preprocess, 54.2ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.7ms\n","Speed: 4.4ms preprocess, 35.7ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.7ms\n","Speed: 4.5ms preprocess, 35.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.7ms\n","Speed: 3.6ms preprocess, 35.7ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 35.6ms\n","Speed: 3.2ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 15 persons, 2 cars, 35.6ms\n","Speed: 3.5ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.9ms\n","Speed: 3.5ms preprocess, 35.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 47.4ms\n","Speed: 2.9ms preprocess, 47.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.6ms\n","Speed: 3.3ms preprocess, 35.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 17 persons, 2 cars, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n","\n","0: 320x640 16 persons, 2 cars, 35.6ms\n","Speed: 3.4ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n","Finished processing for video: /content/drive/MyDrive/Colab Notebooks/soccer_prj/soccer_tracking/soccer_input/for_tracking.mp4\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8oY_VsI4UHoc"},"execution_count":null,"outputs":[]}]}